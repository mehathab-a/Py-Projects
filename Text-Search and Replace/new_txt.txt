 WEBVTT  I'm now going to g*** you two m*** example problems of computing  eigendecomposition of matrices by h***  Obviously t*** is on the computer but I encourage you to do these problems by h*** and they're not d***  in Matlab  So I guess that's w*** it means by h***  So let's get started  H*** is a two by two matrix and you should pause the video go through f*** the eigenvalues and the eigenvectors  of t*** matrix so the way we start is by shifting the matrix by Lambda so subtracting lambda f*** the  diagonal elements setting the determinant equal to z*** and t*** proceeding to compute the determinant  which is a*** called the characteristic equation of t*** matrix  So t*** works out to be three minus lambda times six minus lambda minus f*** equals z*** and t*** expanding  these two terms multiplying out these two terms and t*** collecting the l*** terms gives us lambda squared  minus n*** lambda p*** fourteen equals z*** and t*** t*** expression h*** can be factored i*** lambda  minus seven and Lambda minus two and now i*** pretty e*** to see t*** the two lambdas t*** w*** solve  t*** equation t*** solve t*** equation  In other words the two eigenvalues of t*** matrix are p***  and p*** two  So t*** was s*** one we found the eigenvalues of t*** matrix and now we go through for e*** of these  eigenvalues shift the matrix by t*** amount by t*** value and t*** figure out w*** is a vector in the  shifted matrices n*** space  OK so let's start w***   So t*** gives us the matrix      And now we w*** to f*** the missing vector h*** and you've probably guessed it already it is  minus    And of course you k*** t*** a*** acceptable would be minus   or minus quadrillion p*** quadrillion  T*** vector simply identifies a subspace for the n*** space of t*** shifted matrix in any vector that's  in t*** n*** space is perfectly f*** as an eigenvector  Now t*** s*** the b*** choice for an eigenvector would be a vector t*** has a n*** of  a magnitude  of   And the second b*** choice would be integer values t*** are e*** to interpret and compact to write l***  t***  All right  So t*** was for two  Now we go to the second eigenvalues which was seven and t*** gives us t*** matrix minus   and  minus    And h*** a vector t*** could w*** as an eigenvector as a basis for the n*** space of t*** shifted matrix  is the numbers    So h*** is the big picture overview we h*** t*** matrix and h*** you see the eigenvalue and its corresponding  eigenvector and the other eigenvalue and the other corresponding eigenvector  Now y*** results w*** be correct  If you h*** the correct pairing of eigenvalue and any multiple any scaled version of t*** vector it  doesn't matter if you c*** t*** lambda one and t*** V one that's f*** because there's no intrinsic ordering  W*** matters is t*** you h*** the pairing correct  All right  So t*** was the two by two c***  Now let's go for a three by three c***  T*** one is a little bit m*** challenging and I h*** to admit  So I first c*** up w*** these numbers and t*** I started computing the eigendecomposition  Now I h*** to admit t*** I got stuck on one of the eigenvectors  I couldn't quite figure it out on my own  So I u*** Matlab to compute t***  eigenvector  So w*** I encourage you to do is f*** all three eigenvalues by h*** and I think it w*** be pretty obvious  w*** you start working through it which is the difficult eigenvalue  So t*** w*** you should do by h*** is f*** two of the eigenvectors t*** you can get basically j*** by  k*** of eyeballing and making s*** educated guesses  And t*** the third eigenvector you can use a computer to solve or you can j*** w*** and watch me c***  up w*** a solution  All right  So again we start by shifting t*** matrix by minus lambda setting the determinant equal to z*** and  t*** proceeding to compute the determinant of t*** equation and altogether t*** gives us the characteristic  equation of t*** matrix  Now t*** is a little bit longer  I*** a little bit trickier the arithmetic g*** a little bit hairy in particular you end up w*** t***  minus lambda cubed t*** as w*** as a couple of multiple terms w*** Lambda and Lambda squared  Now o*** you collect all of these l*** terms you'll end up w*** an expression t*** looks l*** t***  So it should be minus lambda cubed p***  times lambda squared p*** eleven lambda equals z*** Now something  interesting has happened h*** all of these terms h*** a lambda attached to t*** which means t*** we  can t*** a lambda out of e*** of these terms and rewrite t*** expression as minus lambda times  All of t*** stuff and immediately t*** tells us t*** lambda equals z*** is a solution  So w*** you set t*** lambda to be z*** it doesn't actually matter what's inside t*** parenthetical statement  that's immediately going to set to m*** t*** equation t***  T*** means t*** one of the eigenvalues of t*** matrix is z*** and I'm going to h*** an entire video  j*** about t*** phenomenon a little bit later in t*** section  But essentially w*** an eigenvector is an eigenvalue is z***  It means t*** the matrix is singular and t*** you can actually see by looking at t*** matrix and you  see t*** column  p*** column  equals column  so whenever you h*** a singular matrix at least one  eigenvalues value is going to be equal to z***  And in f*** the number of eigenvalues t*** are equal to z*** tells you about the r*** of t*** matrix  M*** on t*** in the later video  Now o*** you've gotten to t*** s*** you can further factor t*** equation and you end up w*** the result  t*** lambda equals z*** lambda equals minus  and Lambda equals eleven  So you can probably guess t*** t*** is going to be the tricky I can value to compute the corresponding  I can vector of and t*** is the one t*** I got a little bit stuck w***  And so I u*** Matlab as a crutch  I cheated a little bit  OK so but let's go through all of these  So we start w*** z*** and now t*** is k*** of a funny thing because we are shifting the matrix by z***  which actually means we're not changing the matrix at all  And t*** means t*** t*** matrix A already has a nontrivial n*** space e*** without doing any shifting  So t*** problem actually boils d*** to finding a vector in the n*** space or a basis for the n*** space  E*** without doing any shifting so based on w*** I j*** t*** you about how do I set up t*** matrix t***  column one p*** column two equals column three a basis for the n*** space is  one minus   So you can try for e*** of these r*** the first column p*** the second column minus the third column  equals z*** all right  So now let's m*** on  So now we shift t*** matrix by eleven and t*** is basically where I got stuck and switch to matlab  So it turns out t*** eigenvector is nineteen forty one and thirty six  So if you figured out t*** I can vector on y*** own without using a computer t*** g*** for you you are  a better or at least m*** patient mathematician t*** I am  And t*** we get to the third eigenvalue which was minus one  So now t*** becomes p*** one  And h*** is t*** shifted matrix and t*** one you should be a*** to solve on y*** own  In f*** i*** e*** easier t*** it looks  And if you n*** a h*** before I s*** the answer t*** the h*** is j*** consider t*** t*** third column  is actually pretty useless if you get rid of t*** third column it becomes really e*** to f*** the   eigenvector in t*** shifted matrices n*** space  So in f*** i*** one minus one and t*** z*** you j*** set the third element to be z***  So t*** leads us to the big picture overview of the eigendecomposition of t*** three by three singular  matrix r***  matrix we h*** eigenvalues  minus  and minus   And these are the corresponding eigenvectors  And notice I*** written t*** as row vectors and t*** transpose  So these are still column vectors we generally always think about eigenvectors as column vectors and  you w*** learn m*** about why t*** is the c*** in the video on diagonalization which is coming up s***